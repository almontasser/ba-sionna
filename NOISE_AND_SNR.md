# Noise & SNR in This Repo (Training + Evaluation)

This document explains:
- how **per-antenna SNR** (`snr_db`) is converted to **noise power** (`noise_power = σₙ²`)
- how **random AWGN samples** are generated from `noise_power`
- where noise is injected in the sensing loop during **training** and **evaluation**
- how **post-combining receive SNR** (`SNR_RX`) is computed for metrics/plots

---

## 1) Definitions (what the variables mean)

### `snr_db` (per-antenna SNR)
Throughout the codebase, `snr_db` means **per-antenna SNR** in dB, used to set the noise
variance for the sensing measurements.

The intended normalization follows the paper-style convention (pilot power normalized to 1):

`SNR_ANT = 1 / σₙ²`  ⇒  `σₙ² = 1 / SNR_ANT`

### `noise_power` (a.k.a. `σₙ²`)
`noise_power` is the **complex noise variance** used when generating AWGN for each scalar
measurement `y_t`.

The helper `utils.py:add_complex_noise(signal, noise_power)` uses:
- `n ~ CN(0, σₙ²)` (circularly-symmetric complex Gaussian)
- `Re(n) ~ N(0, σₙ²/2)`, `Im(n) ~ N(0, σₙ²/2)`

So the per-dimension standard deviation is:

`std = sqrt(noise_power / 2)`

### `BF_gain`
Beamforming gain is computed from the channel and beams (linear scale):

`BF_gain = |wᴴ H f|²`

### `SNR_RX` (post-combining receive SNR for satisfaction)
The “satisfaction probability” metric uses the **post-combining** receive SNR:

`SNR_RX = |wᴴ H f|² / σₙ² = BF_gain / noise_power`

In dB:

`SNR_RX(dB) = BF_gain(dB) − 10 log10(noise_power)`

Code: `metrics.py:BeamAlignmentMetrics.update()` stores `snr_rx_db` when `noise_power` is provided.

Because this repo sets `noise_power = 1 / 10^(snr_db/10)`, we also have:

`10 log10(noise_power) = −snr_db`  ⇒  `SNR_RX(dB) = BF_gain(dB) + snr_db`

This is why satisfaction probability can look “good” even if `BF_gain(dB)` is negative:
the threshold is applied to `BF_gain(dB) + snr_db`, not to `BF_gain(dB)` alone.

---

## 2) Training: how noise is generated and used

### 2.1 How `snr_db` is chosen (fixed vs randomized)
Training can use either a fixed SNR or randomized SNR (domain randomization):

- `training/steps.py:sample_snr(config)`:
  - if `Config.SNR_TRAIN_RANDOMIZE=True`, samples `snr_db ~ Uniform(Config.SNR_TRAIN_RANGE)`
  - else uses `Config.SNR_TRAIN` as a constant

Config knobs: `config.py` (`SNR_TRAIN`, `SNR_TRAIN_RANDOMIZE`, `SNR_TRAIN_RANGE`).

### 2.2 How `noise_power` is computed from `snr_db`
The mapping is always:

`snr_linear = 10^(snr_db/10)`  
`noise_power = 1 / snr_linear`

There are two execution paths:

1) **Default training path** (channels generated inside the model):
   - `training/steps.py:train_step()` calls `model(batch_size=..., snr_db=..., training=True)`
   - `models/beam_alignment.py:BeamAlignmentModel.call()` computes `noise_power` from `snr_db`

2) **Precomputed-channel training path** (channels passed into the step):
   - `training/steps.py:train_step(..., channels=...)` computes `noise_power` locally
   - then calls `model.execute_beam_alignment(channels, noise_power, ..., snr_db=snr_db)`

### 2.3 How random noise samples are drawn (AWGN)
Noise samples are generated by:
- `utils.py:add_complex_noise()`, which calls `tf.random.normal(...)` for real+imag parts

So:
- `noise_power` is **deterministic** given `snr_db`
- the actual noise realization is **random** for every call/step unless you fix TF seeds

### 2.4 Where noise is injected (the sensing loop)
Noise is added at each sensing step `t` when generating the scalar measurement:

`y_t = w_tᴴ H_t f_t + n_t`

Code: `models/beam_alignment.py:BeamAlignmentModel.execute_beam_alignment()`
- computes the noiseless scalar `signal = sum(conj(w_t) * (H_t f_t))`
- then does `y_t = add_complex_noise(signal, noise_power)`

The **UE RNN** then takes `y_t` (and the BS beam index) as input for the next step.

Important: the RNN does **not** receive `SNR_RX` as an input anywhere.  
Optionally, it can receive `snr_db` as an extra feature (see `models/ue_controller.py`
and `config.py:UE_INCLUDE_SNR_FEATURE`).

### 2.5 How noise affects the loss
The loss is computed from the **final beamforming gain** (a function of `H` and chosen beams),
not from the noisy measurement directly:

- `metrics.py:compute_loss()` uses `BF_gain = |wᴴ H f|²` (and optionally its normalization)

Noise still matters because it changes the sensed `y_t`, which changes the RNN state and
thus the selected beams.

---

## 3) Evaluation / plotting: how noise is generated and used

Evaluation uses the same `snr_db → noise_power` mapping, but there are two common modes:

### 3.1 “Fresh channels per batch” evaluation
Used by `figures_evaluators/common.py:evaluate_at_snr()`:

- calls `model(batch_size=..., snr_db=..., training=False)`
- `BeamAlignmentModel.call()` computes `noise_power`
- `execute_beam_alignment()` adds AWGN via `add_complex_noise()`
- metrics get `noise_power` from `results["noise_power"]` so they can compute `SNR_RX`

This mode changes both:
- channel realizations `H`
- measurement noise realizations `n`
across batches.

### 3.2 “Fixed channels, vary only noise” evaluation (Fig. 4 style)
Used by `figures_evaluators/common.py:evaluate_at_snr_fixed_channels()`:

- computes `noise_power = 1 / 10^(snr_db/10)` directly in the evaluator
- calls `model.execute_beam_alignment(channels, noise_power, training=False, ...)`
- metrics use the *same* `noise_power` to compute `SNR_RX`

This mode is useful when you want the SNR trend to come mainly from changing the
measurement noise level, not from drawing new channels at each SNR point.

### 3.3 Where `SNR_RX` is computed for plots/metrics
All satisfaction-based plots go through:

- `metrics.py:BeamAlignmentMetrics.update(..., noise_power=...)`
  - computes `snr_rx_db = bf_gain_db - 10log10(noise_power)`
- `metrics.py:BeamAlignmentMetrics.result()`
  - computes satisfaction probability `Pr[SNR_RX(dB) ≥ target_snr_db]`

Figure scripts in `figures_evaluators/*` call the evaluators in `figures_evaluators/common.py`
and plot:
- mean/stdev `BF_gain(dB)`
- satisfaction probability
against `snr_db`.

### 3.4 Which figures use which evaluation mode
- `figures_evaluators/figure4.py` uses `evaluate_at_snr_fixed_channels(...)` so only the **noise level** changes across SNR points.
- `figures_evaluators/figure5.py` uses `evaluate_at_snr(...)`, so both **channels** and **noise** are resampled across batches.

---

## 4) Numerical example (to remove ambiguity)

Assume `snr_db = 10 dB`:
- `snr_linear = 10^(10/10) = 10`
- `noise_power = 1/10 = 0.1`
- per-dimension std in `add_complex_noise()` is `sqrt(0.1/2) ≈ 0.2236`

If your final beamforming gain is `BF_gain(dB) = -25 dB`, then:
- `SNR_RX(dB) = BF_gain(dB) + snr_db = -25 + 10 = -15 dB`

If your final beamforming gain improves to `BF_gain(dB) = -5 dB`, then:
- `SNR_RX(dB) = -5 + 10 = 5 dB`

So even without changing `snr_db`, improving beamforming gain directly improves `SNR_RX`
and thus increases satisfaction probability for any fixed threshold.

---

## 5) Does the channel affect the noise?

Not directly.

- Noise variance is set **only** by `snr_db` via `noise_power = 1/10^(snr_db/10)`.
- The channel affects `BF_gain` (and therefore `SNR_RX`) through `|wᴴ H f|²`.

If you enable large-scale effects (e.g., `Config.ENABLE_PATHLOSS=True`), `H` changes scale
with distance/pathloss, so `BF_gain` (and `SNR_RX`) will depend on the sampled topology.
The noise variance mapping itself remains the same.
